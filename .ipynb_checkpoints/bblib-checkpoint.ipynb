{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Meta_Search_Optimizer:\n",
    "    \n",
    "    '''Meta Search Optimizer\n",
    "       \n",
    "       @init:\n",
    "       max_steps = max number of iterations\n",
    "       verbose = True shows progress bar\n",
    "       \n",
    "       @optimize:\n",
    "           *input:\n",
    "               f = function to be optimized\n",
    "               warning: \n",
    "                   - f.opt = optimal value\n",
    "                   - f.domain = interval to search, e.g. [-5, 5]\n",
    "                   - f.dimension = dimension of the function\n",
    "           *output:\n",
    "               (best_x, number of steps) if optimal point was found else (None, -1)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, meta_model, init_hf_strategy=\"zero\", best_meta_point_strategy=\"lowest\", \n",
    "                 hf_strategy=\"random\", nb_samples=10, size_hf=5, max_steps=100000, verbose=False):\n",
    "        self.meta_model = meta_model\n",
    "        self.init_hf_strategy = init_hf_strategy\n",
    "        self.best_meta_point_strategy = best_meta_point_strategy\n",
    "        self.hf_strategy = hf_strategy\n",
    "        self.nb_samples = nb_samples\n",
    "        self.size_hf = size_hf\n",
    "        self.max_steps = max_steps\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def init_hf(self):\n",
    "        if self.init_hf_strategy == \"zero\":\n",
    "            return np.array([(0,0,0)]*self.size_hf)\n",
    "        \n",
    "    def best_meta_point(self, meta_points, meta_evaluations, hf):\n",
    "        if self.best_meta_point_strategy == \"lowest\":\n",
    "            meta_evaluations = meta_evaluations.reshape(self.nb_samples)\n",
    "            indexes = np.argsort(meta_evaluations)\n",
    "            hf = np.array(hf)\n",
    "            if hf.size == 0:\n",
    "                return meta_points[indexes[0]]\n",
    "            for idx in indexes:\n",
    "                if meta_points[idx] not in hf[:, 0:2]:\n",
    "                    return meta_points[idx]\n",
    "            return meta_points[indexes[0]]\n",
    "        if self.best_meta_point_strategy == \"random\":\n",
    "            index = np.random.randint(0, len(meta_points))\n",
    "            return meta_points[index]\n",
    "        \n",
    "    def optimize(self, f):\n",
    "        \n",
    "        #Init best values:\n",
    "        best_x = [None] * f.dimension \n",
    "        best_y = 99999.0\n",
    "        \n",
    "        #Init history\n",
    "        hf = []\n",
    "        curr_hf = self.init_hf()\n",
    "        \n",
    "        #Define Iterator:\n",
    "        if self.verbose:\n",
    "            iterator = tqdm(range(self.max_steps))\n",
    "        else:\n",
    "            iterator = range(self.max_steps)\n",
    "        \n",
    "        #Iteration:\n",
    "        for step in iterator:\n",
    "            \n",
    "            #1) Select n random points to be evaluated by meta-model\n",
    "            meta_points = (f.domain[1] - f.domain[0]) * np.random.random_sample((self.nb_samples, f.dimension)) + f.domain[0]\n",
    "            \n",
    "            #2) Meta-evaluate points in meta-model\n",
    "            meta_evaluations = self.meta_model.predict(meta_points, curr_hf)\n",
    "            \n",
    "            #3) Get the next point (x_t+1)\n",
    "            new_x = self.best_meta_point(meta_points, meta_evaluations, hf)\n",
    "\n",
    "            #4) Evaluate this point in function\n",
    "            new_y = f(new_x)\n",
    "            \n",
    "            if step % 1000 == 0:\n",
    "                pass\n",
    "                #print(meta_points)\n",
    "                #print(meta_evaluations)\n",
    "                #print(new_x)\n",
    "                #print(new_y)\n",
    "                #print()\n",
    "            \n",
    "            #Check if it is an improvement:\n",
    "            if new_y < best_y: \n",
    "                best_y = new_y\n",
    "                best_x = new_x\n",
    "                \n",
    "                #Check if it is a solution:\n",
    "                if round(best_y, 2) == f.fopt:\n",
    "                    return (list(best_x), step)\n",
    "\n",
    "            #Save train data:\n",
    "            #dataset.append(np.array([np.array(best_point), np.array(curr_hist), np.array(f_eval)]))\n",
    "\n",
    "            #5) Add this info in your history\n",
    "            info = (new_x[0], new_x[1], new_y)  #TODO: here it's only 2D problem!\n",
    "            hf.append(info)\n",
    "\n",
    "            #6) Select next current history\n",
    "            curr_hf = self.select_hf(hf)\n",
    "            \n",
    "        return (None, -1)\n",
    "            \n",
    "    def select_hf(self, hf):\n",
    "\n",
    "        if self.hf_strategy == \"gagne\":\n",
    "            \n",
    "            if len(hf) < self.size_hf:\n",
    "                choices = np.random.choice(len(hf), self.size_hf)\n",
    "                curr_pop = np.array([hf[i] for i in choices])\n",
    "                return curr_pop\n",
    "            else:\n",
    "                #50% top:\n",
    "                top50 = sorted(range(len(hf)), key=lambda i: hf[i], reverse=True)[-self.size_hf//2:]\n",
    "\n",
    "                #50% random:\n",
    "                random50 = [random.randint(0, len(hf)-1) for i in range(self.size_hf//2)]\n",
    "\n",
    "                all_indexes = sorted(top50 + random50)\n",
    "                curr_pop = [(hf[ind][0], hf[ind][1], hf[ind][2]) for ind in all_indexes]\n",
    "\n",
    "                return np.array(curr_pop)\n",
    "\n",
    "        elif self.hf_strategy == \"random\":\n",
    "            hf = np.array(hf)\n",
    "            idx = np.random.choice(len(hf), self.size_hf)\n",
    "            return hf[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random_Search_Optimizer:\n",
    "    \n",
    "    '''Random Search Optimizer\n",
    "       \n",
    "       @init:\n",
    "       max_steps = max number of iterations\n",
    "       verbose = True shows progress bar\n",
    "       \n",
    "       @optimize:\n",
    "           *input:\n",
    "               f = function to be optimized\n",
    "               warning: \n",
    "                   - f.opt = optimal value\n",
    "                   - f.domain = interval to search, e.g. [-5, 5]\n",
    "                   - f.dimension = dimension of the function\n",
    "           *output:\n",
    "               (best_x, number of steps) if optimal point was found else (None, -1)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, max_steps=100000, verbose=False):\n",
    "        self.max_steps = max_steps\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def optimize(self, f):\n",
    "        \n",
    "        #Init best values:\n",
    "        best_x = [None] * f.dimension \n",
    "        best_y = 99999.0\n",
    "\n",
    "        #Define Iterator:\n",
    "        if self.verbose:\n",
    "            iterator = tqdm(range(self.max_steps))\n",
    "        else:\n",
    "            iterator = range(self.max_steps)\n",
    "        \n",
    "        #Iteration:\n",
    "        for step in iterator:\n",
    "\n",
    "            #Choose random x and evaluate it:\n",
    "            new_x = (f.domain[1] - f.domain[0]) * np.random.random_sample(f.dimension) + f.domain[0]\n",
    "            new_y = f(new_x)\n",
    "\n",
    "            #Check if it is an improvement:\n",
    "            if new_y < best_y: \n",
    "                best_y = new_y\n",
    "                best_x = new_x\n",
    "\n",
    "                #Check if it is a solution:\n",
    "                if round(best_y, 2) == f.fopt:\n",
    "                    return (list(best_x), step)\n",
    "\n",
    "        return (None, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    \n",
    "    '''Evaluator\n",
    "       \n",
    "       @init:\n",
    "       nb_trials = max number of iterations\n",
    "       verbose = True shows progress bar\n",
    "       \n",
    "       @optimize:\n",
    "           *input:\n",
    "               f = function to be optimized\n",
    "               warning: \n",
    "                   - f.opt = optimal value\n",
    "                   - f.domain = interval to search, e.g. [-5, 5]\n",
    "                   - f.dimension = dimension of the function\n",
    "                optimizer = optimize that will be used to optimize the function\n",
    "           *output:\n",
    "               if optimal point was found in all iterations: \n",
    "                   {\"mean\": mean, \"stdev\": stdev}\n",
    "               else: \n",
    "                   {\"mean\": None, \"stdev\": None}\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, nb_trials=100, verbose=1):\n",
    "        self.nb_trials = nb_trials\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def evaluate(self, f, optimizer):\n",
    "        \n",
    "        sum_x = 0\n",
    "        sum_x2 = 0\n",
    "        \n",
    "        #Define Iterator:\n",
    "        if self.verbose:\n",
    "            iterator = tqdm(range(self.nb_trials))\n",
    "        else:\n",
    "            iterator = range(self.nb_trials)\n",
    "        \n",
    "        #Iteration:\n",
    "        for trial in iterator:\n",
    "            bestx, step = optimizer.optimize(f)\n",
    "            try:\n",
    "                bestx, step = optimizer.optimize(f)\n",
    "            except:\n",
    "                return {\"mean\": None, \"stdev\": None}\n",
    "            \n",
    "            sum_x += step\n",
    "            sum_x2 += step*step\n",
    "\n",
    "        mean = sum_x / self.nb_trials\n",
    "        stdev = np.sqrt((sum_x2 / self.nb_trials) - (mean * mean)) \n",
    "        \n",
    "        return {\"mean\": mean, \"stdev\": stdev}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from metamodel.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import bbobbenchmarks as bn\n",
    "\n",
    "import nbimporter\n",
    "from metamodel import *\n",
    "\n",
    "#Define problem\n",
    "f = bn.F1(1)\n",
    "f.domain = [-5, 5]\n",
    "f.dimension = 2\n",
    "\n",
    "#Define evaluator\n",
    "evaluator = Evaluator(nb_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean': 4224.0, 'stdev': 3217.971317460738}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search_opt = Random_Search_Optimizer()\n",
    "\n",
    "#random_search_opt.optimize(f)\n",
    "#evaluator.evaluate(f, random_search_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.90459727  0.67335939]\n",
      " [-2.11128169 -4.24100511]\n",
      " [ 2.52859757  2.54279248]\n",
      " [-0.77844982 -1.2216742 ]\n",
      " [ 4.64025329  3.07043744]\n",
      " [-4.22757181 -2.12780147]\n",
      " [-2.30064924  0.90814192]\n",
      " [ 4.12799274 -4.59574348]\n",
      " [ 1.3307194  -3.75036278]\n",
      " [-2.67867931 -4.46393241]]\n",
      "[[ 0.0225195 ]\n",
      " [ 0.04782422]\n",
      " [ 0.01776268]\n",
      " [ 0.01595832]\n",
      " [ 0.02483957]\n",
      " [ 0.04129349]\n",
      " [ 0.04543367]\n",
      " [ 0.00344456]\n",
      " [-0.00258816]\n",
      " [ 0.05631971]]\n",
      "[-2.30064924  0.90814192]\n",
      "90.26408815045502\n",
      "\n",
      "[[-4.25992356  4.56884808]\n",
      " [ 1.60435482  1.11356316]\n",
      " [ 3.06300935  1.65346697]\n",
      " [-1.88484648  0.37425113]\n",
      " [-0.67170673  2.95388588]\n",
      " [-4.52399902 -0.58893054]\n",
      " [-4.54270078  2.57206919]\n",
      " [-1.15446214  0.67872842]\n",
      " [-2.99143013  4.17178329]\n",
      " [ 1.89971256  0.96536669]]\n",
      "[[-2.4512095]\n",
      " [-2.7724771]\n",
      " [-2.8293662]\n",
      " [-2.627602 ]\n",
      " [-2.6409926]\n",
      " [-2.5220537]\n",
      " [-2.470664 ]\n",
      " [-2.6555443]\n",
      " [-2.5168724]\n",
      " [-2.7880955]]\n",
      "[1.60435482 1.11356316]\n",
      "86.4612493009176\n",
      "\n",
      "[[ 1.08952513  4.71262453]\n",
      " [-3.40193925  1.63013475]\n",
      " [ 3.0573493   2.44728558]\n",
      " [-0.06596459 -4.50732915]\n",
      " [ 3.14641415  1.97866405]\n",
      " [ 1.35570022  1.96604774]\n",
      " [ 3.97989719 -2.17818975]\n",
      " [-0.83407847  4.06310805]\n",
      " [ 1.95568654  0.51549818]\n",
      " [-0.29779282  1.97258505]]\n",
      "[[-2.0252295]\n",
      " [-1.8835006]\n",
      " [-2.1586823]\n",
      " [-2.1513848]\n",
      " [-2.1718183]\n",
      " [-2.0905838]\n",
      " [-2.2903223]\n",
      " [-1.9523134]\n",
      " [-2.1460028]\n",
      " [-2.015222 ]]\n",
      "[-0.83407847  4.06310805]\n",
      "107.90874488503673\n",
      "\n",
      "[[-2.02688688  1.37747391]\n",
      " [ 2.10757514  0.64673069]\n",
      " [ 0.5705598  -3.29852649]\n",
      " [-1.19798092  4.26181805]\n",
      " [ 3.24669408  0.33267644]\n",
      " [ 2.49857049 -3.10797048]\n",
      " [ 2.8751878   2.08369639]\n",
      " [ 1.27641441  0.91151922]\n",
      " [ 3.15047198 -0.35518918]\n",
      " [-1.15266828  0.51667381]]\n",
      "[[ 0.04865842]\n",
      " [ 0.00949396]\n",
      " [ 0.00608338]\n",
      " [ 0.01394321]\n",
      " [ 0.02161949]\n",
      " [-0.00125047]\n",
      " [ 0.016789  ]\n",
      " [ 0.00745618]\n",
      " [ 0.02427078]\n",
      " [ 0.02355151]]\n",
      "[ 0.5705598  -3.29852649]\n",
      "84.1679636290524\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "meta_search_opt_random = Meta_Search_Optimizer(model,best_meta_point_strategy=\"random\")\n",
    "\n",
    "#meta_search_opt_random.optimize(f)\n",
    "evaluator.evaluate(f, meta_search_opt_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "#model = load_model('metamodel.h5')\n",
    "#model = Model(model)\n",
    "\n",
    "import random\n",
    "model = Model()\n",
    "\n",
    "\n",
    "print(model.model.layers[2].input_shape)\n",
    "meta_search_opt_highest = Meta_Search_Optimizer(model,best_meta_point_strategy=\"lowest\",hf_strategy=\"gagne\",verbose=True)\n",
    "\n",
    "meta_search_opt_highest.optimize(f)\n",
    "#evaluator.evaluate(f, meta_search_opt_highest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
